# Robust_RL_for_Algorithmic_Trading_ECE542
Reinforcement learning (RL) has shown promise in financial applications such as algorithmic trading. However, the high-dimensional nature of market data introduces the curse of dimensionality, making neural network-based function approximators essential. While Deep Q-Networks (DQNs) have gained popularity for learning trading strategies, real-world financial markets are inherently uncertainâ€”exhibiting dynamic variability, stochastic noise, and even adversarial manipulations. These factors can severely degrade the reliability of standard DQN-based approaches. This project focuses on developing a provably robust Deep Q-Network that remains effective in the presence of adversarial contaminations and noisy temporal data. By incorporating robustness at the algorithmic level, the goal is to enhance the dependability of reinforcement learning in volatile and adversarial financial environments, laying the foundation for the next generation of robust deep Q-learning algorithms.
<table>
<tr>
  <td>
    <img src="https://github.com/sreejeetm1729/Robust_RL_for_Algorithmic_Trading_ECE542/blob/main/NN%20Project%20Poster.jpg" style="width:500px">
 </td>
</tr>

